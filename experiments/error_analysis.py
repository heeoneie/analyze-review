"""
Level 3: ì—ëŸ¬ ë¶„ì„ & ê°œì„ 
í‹€ë¦° ì¼€ì´ìŠ¤ë¥¼ ë¶„ì„í•˜ì—¬ íŒ¨í„´ì„ ì°¾ê³  í”„ë¡¬í”„íŠ¸ ê°œì„ 
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import pandas as pd
import json
from collections import Counter, defaultdict
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns

class ErrorAnalyzer:
    def __init__(self, evaluation_results_file):
        """
        Args:
            evaluation_results_file: evaluate.py ì‹¤í–‰ ê²°ê³¼ íŒŒì¼ ê²½ë¡œ
        """
        self.results_file = evaluation_results_file
        self.errors = []
        self.ground_truth_df = None

    def load_evaluation_results(self):
        """í‰ê°€ ê²°ê³¼ ë¡œë“œ"""
        with open(self.results_file, 'r', encoding='utf-8') as f:
            data = json.load(f)

        # ì—ëŸ¬ ì¼€ì´ìŠ¤ íŒŒì¼ ì°¾ê¸°
        error_file = None
        if '_metrics_' in self.results_file:
            error_file = self.results_file.replace('_metrics_', '_errors_')
        elif self.results_file.endswith('_metrics.json'):
            error_file = self.results_file.replace('_metrics.json', '_errors.json')

        if error_file and os.path.exists(error_file):
            with open(error_file, 'r', encoding='utf-8') as f:
                self.errors = json.load(f)

        return data

    def analyze_confusion_pairs(self):
        """ìì£¼ í˜¼ë™ë˜ëŠ” ì¹´í…Œê³ ë¦¬ ìŒ ë¶„ì„"""
        print("\n" + "="*80)
        print("  1. í˜¼ë™ ì¹´í…Œê³ ë¦¬ ìŒ ë¶„ì„")
        print("="*80)

        confusion_pairs = Counter()

        for error in self.errors:
            true_label = error['true_label']
            pred_label = error['predicted_label']
            pair = tuple(sorted([true_label, pred_label]))
            confusion_pairs[pair] += 1

        print("\nê°€ì¥ ë§ì´ í˜¼ë™ë˜ëŠ” ì¹´í…Œê³ ë¦¬ ìŒ (Top 5):\n")
        print("{:<25} {:<25} {:<10}".format("True Label", "Predicted Label", "Count"))
        print("-" * 80)

        for (label1, label2), count in confusion_pairs.most_common(5):
            print(f"{label1:<25} â†” {label2:<25} {count:<10}")

        return confusion_pairs

    def analyze_error_patterns(self):
        """ì—ëŸ¬ íŒ¨í„´ ë¶„ì„"""
        print("\n" + "="*80)
        print("  2. ì—ëŸ¬ íŒ¨í„´ ë¶„ì„")
        print("="*80)

        patterns = {
            'review_length': defaultdict(int),
            'rating': defaultdict(int),
            'categories': defaultdict(int)
        }

        for error in self.errors:
            # ë¦¬ë·° ê¸¸ì´ë³„ ì—ëŸ¬
            text_length = len(error['review_text'])
            if text_length < 50:
                length_category = 'very_short'
            elif text_length < 150:
                length_category = 'short'
            elif text_length < 300:
                length_category = 'medium'
            else:
                length_category = 'long'

            patterns['review_length'][length_category] += 1

            # í‰ì ë³„ ì—ëŸ¬
            if 'rating' in error:
                patterns['rating'][str(error['rating'])] += 1

            # ì¹´í…Œê³ ë¦¬ë³„ ì—ëŸ¬ ë°œìƒ ë¹ˆë„
            patterns['categories'][error['true_label']] += 1

        # ë¦¬ë·° ê¸¸ì´ë³„ ì—ëŸ¬
        print("\nğŸ“ ë¦¬ë·° ê¸¸ì´ë³„ ì—ëŸ¬ ë¶„í¬:")
        for length, count in sorted(patterns['review_length'].items()):
            print(f"   {length:>12}: {count:>3}ê±´")

        # í‰ì ë³„ ì—ëŸ¬
        if patterns['rating']:
            print("\nâ­ í‰ì ë³„ ì—ëŸ¬ ë¶„í¬:")
            for rating, count in sorted(patterns['rating'].items()):
                print(f"   {rating}ì : {count:>3}ê±´")

        # ì¹´í…Œê³ ë¦¬ë³„ ì—ëŸ¬
        print("\nğŸ·ï¸  ì¹´í…Œê³ ë¦¬ë³„ ì—ëŸ¬ ë°œìƒ (Top 5):")
        for category, count in Counter(patterns['categories']).most_common(5):
            print(f"   {category:<25}: {count:>3}ê±´")

        return patterns

    def identify_common_keywords(self):
        """ì—ëŸ¬ ì¼€ì´ìŠ¤ì˜ ê³µí†µ í‚¤ì›Œë“œ ë¶„ì„"""
        print("\n" + "="*80)
        print("  3. ì—ëŸ¬ ì¼€ì´ìŠ¤ ê³µí†µ í‚¤ì›Œë“œ")
        print("="*80)

        # Stopwords ì •ì˜
        stopwords = {
            'the', 'a', 'an', 'is', 'are', 'was', 'were', 'be', 'been', 'being',
            'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could',
            'should', 'may', 'might', 'must', 'shall', 'can', 'need', 'dare',
            'ought', 'used', 'to', 'of', 'in', 'for', 'on', 'with', 'at', 'by',
            'from', 'as', 'into', 'through', 'during', 'before', 'after', 'above',
            'below', 'between', 'under', 'again', 'further', 'then', 'once',
            'here', 'there', 'when', 'where', 'why', 'how', 'all', 'each', 'few',
            'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only',
            'own', 'same', 'so', 'than', 'too', 'very', 'just', 'and', 'but',
            'if', 'or', 'because', 'until', 'while', 'this', 'that', 'these',
            'those', 'am', 'it', 'its', 'i', 'me', 'my', 'myself', 'we', 'our',
            'you', 'your', 'he', 'him', 'his', 'she', 'her', 'they', 'them',
            'what', 'which', 'who', 'whom', 'also', 'get', 'got', 'like', 'even'
        }

        # í˜¼ë™ ìŒë³„ë¡œ ê³µí†µ í‚¤ì›Œë“œ ì°¾ê¸°
        confusion_keywords = defaultdict(list)
        confusion_top_keywords = {}

        for error in self.errors:
            key = f"{error['true_label']} â†’ {error['predicted_label']}"
            confusion_keywords[key].append(error['review_text'])

        # ìƒìœ„ 3ê°œ í˜¼ë™ ìŒë§Œ ë¶„ì„
        top_confusions = Counter()
        for error in self.errors:
            key = f"{error['true_label']} â†’ {error['predicted_label']}"
            top_confusions[key] += 1

        print("\nì£¼ìš” í˜¼ë™ ì¼€ì´ìŠ¤ì˜ íŠ¹ì§•:")
        for confusion, count in top_confusions.most_common(3):
            print(f"\n{confusion} ({count}ê±´):")
            reviews = confusion_keywords[confusion]

            # í† í°í™” ë° ì •ê·œí™”
            all_tokens = []
            for review in reviews:
                # ì†Œë¬¸ìë¡œ ë³€í™˜, ì•ŒíŒŒë²³ë§Œ ì¶”ì¶œ
                tokens = review.lower().split()
                # íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° í•„í„°ë§
                cleaned_tokens = []
                for tok in tokens:
                    clean_tok = ''.join(c for c in tok if c.isalpha())
                    # ê¸¸ì´ 2 ì´ìƒ, stopword ì•„ë‹Œ ê²ƒë§Œ
                    if len(clean_tok) >= 2 and clean_tok not in stopwords:
                        cleaned_tokens.append(clean_tok)
                all_tokens.extend(cleaned_tokens)

            # ìƒìœ„ 10ê°œ í‚¤ì›Œë“œ ì¶”ì¶œ
            top_keywords = [w for w, _ in Counter(all_tokens).most_common(10)]
            confusion_top_keywords[confusion] = top_keywords
            print(f"   í‚¤ì›Œë“œ: {', '.join(top_keywords[:5])}")

            # ì§§ì€ ì˜ˆì‹œ 3ê°œë§Œ
            for i, review in enumerate(reviews[:3], 1):
                print(f"   {i}. {review[:100]}...")

        return {"examples": dict(confusion_keywords), "keywords": confusion_top_keywords}

    def suggest_improvements(self, confusion_pairs, patterns):
        """ê°œì„  ë°©ì•ˆ ì œì•ˆ"""
        print("\n" + "="*80)
        print("  4. ê°œì„  ë°©ì•ˆ ì œì•ˆ")
        print("="*80)

        suggestions = []

        # 1. í˜¼ë™ ìŒ ê¸°ë°˜ ì œì•ˆ
        top_confusion = confusion_pairs.most_common(1)[0]
        if top_confusion:
            pair, count = top_confusion
            suggestion = {
                'issue': f"'{pair[0]}' ì™€ '{pair[1]}' í˜¼ë™ ({count}ê±´)",
                'solution': "í”„ë¡¬í”„íŠ¸ì— ë‘ ì¹´í…Œê³ ë¦¬ì˜ ëª…í™•í•œ ì°¨ì´ì ì„ ì˜ˆì‹œì™€ í•¨ê»˜ ì¶”ê°€",
                'example': f"- '{pair[0]}': [êµ¬ì²´ì  ì˜ˆì‹œ]\n- '{pair[1]}': [êµ¬ì²´ì  ì˜ˆì‹œ]"
            }
            suggestions.append(suggestion)

        # 2. ë¦¬ë·° ê¸¸ì´ ê¸°ë°˜ ì œì•ˆ
        if 'very_short' in patterns['review_length']:
            count = patterns['review_length']['very_short']
            if count > len(self.errors) * 0.2:  # 20% ì´ìƒ
                suggestion = {
                    'issue': f"ì§§ì€ ë¦¬ë·°(<50ì)ì—ì„œ ì—ëŸ¬ ë§ìŒ ({count}ê±´)",
                    'solution': "ì§§ì€ ë¦¬ë·°ì— ëŒ€í•œ íŠ¹ë³„ ì²˜ë¦¬ ì¶”ê°€",
                    'example': "- ì •ë³´ê°€ ë¶€ì¡±í•œ ê²½ìš° 'other' ì¹´í…Œê³ ë¦¬ ì‚¬ìš©\n- ë§¥ë½ ì¶”ë¡  ìµœì†Œí™”"
                }
                suggestions.append(suggestion)

        # 3. íŠ¹ì • ì¹´í…Œê³ ë¦¬ ì—ëŸ¬ ë§ìŒ
        category_errors = Counter(patterns['categories'])
        if category_errors:
            top_error_category, count = category_errors.most_common(1)[0]
            if count > len(self.errors) * 0.15:  # 15% ì´ìƒ
                suggestion = {
                    'issue': f"'{top_error_category}' ì¹´í…Œê³ ë¦¬ì—ì„œ ì—ëŸ¬ ë§ìŒ ({count}ê±´)",
                    'solution': f"'{top_error_category}' ì •ì˜ë¥¼ ëª…í™•íˆ í•˜ê³  Few-shot ì˜ˆì‹œ ì¶”ê°€",
                    'example': "í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ ëŒ€í‘œì ì¸ 3-5ê°œ ì˜ˆì‹œë¥¼ í”„ë¡¬í”„íŠ¸ì— í¬í•¨"
                }
                suggestions.append(suggestion)

        # ì¶œë ¥
        print("\nğŸ’¡ ì¶”ì²œ ê°œì„  ì‚¬í•­:\n")
        for i, sug in enumerate(suggestions, 1):
            print(f"{i}. ë¬¸ì œ: {sug['issue']}")
            print(f"   í•´ê²°: {sug['solution']}")
            print(f"   ì˜ˆì‹œ:\n   {sug['example']}")
            print()

        return suggestions

    def create_error_report(self):
        """ì—ëŸ¬ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        os.makedirs('results', exist_ok=True)

        if not self.errors:
            print("\nâš ï¸  ì—ëŸ¬ ì¼€ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. í‰ê°€ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
            return

        print("="*80)
        print(f"  ì—ëŸ¬ ë¶„ì„ ë¦¬í¬íŠ¸ (ì´ {len(self.errors)}ê±´)")
        print("="*80)

        # ë¶„ì„ ì‹¤í–‰
        confusion_pairs = self.analyze_confusion_pairs()
        patterns = self.analyze_error_patterns()
        keywords = self.identify_common_keywords()
        suggestions = self.suggest_improvements(confusion_pairs, patterns)

        # ê²°ê³¼ ì €ì¥
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        confusion_pairs_serialized = [
            {"label_a": a, "label_b": b, "count": count}
            for (a, b), count in confusion_pairs.most_common()
        ]
        report = {
            'total_errors': len(self.errors),
            'confusion_pairs': confusion_pairs_serialized,
            'keywords': keywords,
            'patterns': {
                'review_length': dict(patterns['review_length']),
                'rating': dict(patterns['rating']),
                'categories': dict(patterns['categories'])
            },
            'suggestions': suggestions,
            'timestamp': timestamp
        }

        output_file = f'results/error_analysis_{timestamp}.json'
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        print("\n" + "="*80)
        print(f"  ë¦¬í¬íŠ¸ ì €ì¥: {output_file}")
        print("="*80)

        return report


def main():
    import argparse

    parser = argparse.ArgumentParser(description='ì—ëŸ¬ ì¼€ì´ìŠ¤ ë¶„ì„')
    parser.add_argument('--results', type=str,
                        help='í‰ê°€ ê²°ê³¼ íŒŒì¼ ê²½ë¡œ (ì˜ˆ: results/baseline_metrics_xxx.json)')
    args = parser.parse_args()

    if args.results:
        results_file = args.results
        if not os.path.exists(results_file):
            print("\nâŒ ì§€ì •í•œ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print(f"ê²½ë¡œ: {results_file}")
            return
    else:
        # ê°€ì¥ ìµœê·¼ ê²°ê³¼ íŒŒì¼ ìë™ ì°¾ê¸°
        results_dir = 'results'
        if os.path.exists(results_dir):
            metric_files = [
                f for f in os.listdir(results_dir)
                if f.endswith('.json') and '_metrics' in f
            ]
            if metric_files:
                # ê°€ì¥ ìµœê·¼ íŒŒì¼
                metric_files.sort(reverse=True)
                results_file = os.path.join(results_dir, metric_files[0])
                print(f"\nğŸ“‚ ì‚¬ìš©í•  ê²°ê³¼ íŒŒì¼: {results_file}\n")
            else:
                print("\nâŒ í‰ê°€ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                print("ë¨¼ì € evaluation/evaluate.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
                return
        else:
            print("\nâŒ results ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            print("ë¨¼ì € evaluation/evaluate.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
            return

    analyzer = ErrorAnalyzer(results_file)
    analyzer.load_evaluation_results()
    analyzer.create_error_report()


if __name__ == "__main__":
    main()
